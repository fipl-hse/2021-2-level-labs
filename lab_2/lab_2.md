# Лабораторная работа №2

Данная лабораторная работа предполагает расширение полученных 
знаний детектирования (классификации) неизвестного текста.
Для этого будут использоваться подходы машинного обучения (алгоритм KNN).

## Дано

1. Папка `profiles` - три больших текста на английском, немецком и латинском языках для построения словаря языковых профилей.
2. Папка `dataset` - набор данных с текстами на неизвестном и известных языках. 
   - тексты на известных языках для обучения классификатора - `known_samples_eng/de/lat.txt`. 
   По 5 текстов на каждый язык. В каждом файле тексты разделены ключевым словом `[TEXT]`.
   - тексты на неизвестных языках для предсказания языка - `unknown_samples.txt`.
   Разделенные точкой 24 предложения. Для каждого предложения нужно классифицировать язык.
3. Необходимо написать программу-классификатор, 
которая сможет определить (классифицировать), на каком языке написан неизвестный текст (в нашем случае каждое
предложение из файла `unknown_samples.txt`).

**_Важно:_** в файле `start.py` вы должны написать код, определяющий язык неизвестного текста. 
Для этого реализуйте функции в модуле `main.py` и импортируйте их в `start.py`.
Весь код, выполняющий детектирование языка, должен быть выполнен в блоке `__main__:`.

В рамках данной лабораторной работы **НЕЛЬЗЯ использовать сторонние модули и модуль collections.**

## Ход работы

### Шаг 0. Подготовить рабочее окружение

Импортируйте уже написанные в рамках первой лабораторной работы функции:
- `tokenize`
- `remove_stop_words`

Импортированные функции используются для базовой обработки заданных текстов.

### Шаг 1. Получить частотный словарь для одного текста

Прежде чем научить компьютер классифицировать текст нужно представить этот текст
в удобном для чтения компьютером виде. Из первой лабораторной работы мы уже знакомы с
принципом работы языковых профилей. Языковые профили и позволят нам хранить представление
о текстах в удобной для чтения машиной формой. Построим языковые профили. 

Функция принимает на вход список слов.

Функция возвращает словарь типа: *{x:n}*,
где *x* - слово, а *n* - частота появления слова в тексте, разделенная на общее количество слов в тексте.

Если на вход подаются некорректные значения, возвращается `None`.

Интерфейс:
```py
def get_freq_dict(tokens: list) -> dict or None:
  pass
```

### Шаг 2. Получить языковые профили для каждого известного текста

Функция принимает на вход корпус известных текстов, 
а также список соответствующих меток языков этих текстов, например:
```py
corpus = [
    ['the', 'boy', 'is', 'playing', 'football'],
    ['der', 'junge', 'der', 'fussball', 'spielt']
]

labels = ['eng', 'de']
```
Функция возвращает словарь, состоящий из языковых профилей-словарей 
всех известных языков, где ключ - метка языка, а значение - 
словарь частот слов этого языка (мешок слов).

```py
language_profiles = {
    'eng': {'the': 0.2, 'boy': 0.2, 'is': 0.2, 'playing': 0.2, 'football': 0.2},
    'de': {'der': 0.4, 'junge': 0.2, 'fussball': 0.2, 'spielt': 0.2}
}
```

Если на вход подаются некорректные значения, возвращается `None`.

В данной функции необходимо использовать функцию `get_freq_dict`.

Интерфейс:
```py
def get_language_profiles(texts_corpus: list, language_labels: list) -> dict or None:
  pass
```

### Шаг 3. Получить список уникальных токенов для заданного словаря

Функция принимет на вход словарь языковых профилей.

```py
language_profiles = {
    'eng': {'the': 0.2, 'boy': 0.2, 'is': 0.2, 'playing': 0.2, 'football': 0.2},
    'de': {'der': 0.4, 'junge': 0.2, 'fussball': 0.2, 'spielt': 0.2}
}
```

Функция возвращает список всех уникальных слов по заданному словарю языковых профилей.
Этот список должен быть отсортирован по алфавиту, так как в словаре нет порядка хранения элементов.
Например, для словаря языковых профилей будут получены следующие уникальные слова:

```py
features = ['boy', 'der', 'football', 'fussball', 'is', 'junge', 'playing', 'spielt', 'the']
```

Если на вход подаются некорректные значения, возвращается `None`.

Интерфейс:
```py
def get_language_features(language_profiles: dict) -> list or None:
  pass
```

### Шаг 4. Получить вектор для заданного текста (Выполнение шагов 1-4 соответствует 4 баллам)

После того, как мы собрали языковые профили для каждого языка,
мы можем векторизовать любые интересующие нас тексты на основе полученных языковых профилей.
Вектор - это определенный способ представления текста в виде чисел, 
которые отражают различные особенности исходного текста.
В данном случае каждому заданному слову в соответствие ставится его 
относительная частота встречаемости в словаре языковых профилей.

Функция принимает на вход токенизированный текст.
Мы векторизуем заданный текст используя собранный нами словарь языковых профилей, например:

```py
original_text = ['this', 'boy', 'is', 'playing', 'football']

language_profiles = {
    'eng': {'the': 0.2, 'boy': 0.2, 'is': 0.2, 'playing': 0.2, 'football': 0.2},
    'de': {'der': 0.4, 'junge': 0.2, 'fussball': 0.2, 'spielt': 0.2}
}
```

Функция возвращает вектор частот для заданного текста в виде списка.
За основу вектора берутся уникальные слова языковых профилей, 
полученные в функции `get_language_features`. Если уникальное слово присутствует в заданном тексте, 
то на его позицию ставится частота этого слова в словаре языковых профилей, 
если уникального слова нет в заданном тексте, то на его позицию ставится `0`. 
Если уникальное слово присутсвует сразу в нескольких языковых профилях, тогда нужно
выбрать максимальную частоту из всех вариантов.
Для заданного текста и словаря языковых профилей получится следующий вывод:

```py
text_vector = [0.2, 0, 0.2, 0, 0.2, 0, 0.2, 0, 0]
```

Если на вход подаются некорректные значения, возвращается `None`.

В данной функции необходимо использовать функцию `get_language_features`.
Длина полученного вектора  всегда равна длине списка уникальных слов языковых профилей.

Интерфейс:
```py
def get_text_vector(original_text: list, language_profiles: dict) -> list or None:
    pass
```

### Шаг 5. Расширение алгоритма

В предыдущих шагах мы подготовили языковые профили, 
а также научились преобразовывать любые тексты в векторы
на основе имеющегося словаря языковых профилей.

### Шаг 5.1. Получить расстояние между двумя векторами

Особенность векторов заключается в том, что мы можем их сравнивать друг с другом,
например, найти между двумя векторами текстов расстояние. Иными словами сказать,
насколько два текста близки (похожи) друг к другу. Для этого нам понадобится
реализовать метрику подсчета расстояния между двумя текстами:

<img src="https://latex.codecogs.com/gif.latex?dist(a,&space;b)&space;=&space;\sqrt{\sum_{i=1}^{n}\left&space;(&space;a_{i}&space;-&space;b_{i}&space;\right)^{2}}" title="dist(a, b) = \sqrt{\sum_{i=1}^{n}\left ( a_{i} - b_{i} \right)^{2}}" />

Функция принимает на вход два вектора.

Функция возвращает значение типа `float`. Чем меньше это значение,
тем ближе два заданных вектора на координатной плоскости, а соответственно
и ближе два текста, закодированные в них. 
Например для двух текстовых векторов получится значение близости `0.7349149610669251`:

```py
unknown_text_vector = [0.2, 0, 0.2, 0, 0.2, 0, 0.2, 0, 0]
known_text_vector = [0, 0.2, 0, 0.1, 0, 0.49, 0, 0.3, 0]
```

Если на вход подаются некорректные значения, возвращается `None`.

Интерфейс:
```py
def calculate_distance(unknown_text_vector: list, known_text_vector: list) -> float or None:
    pass
```

### Шаг 6. Сравнить вектор неизвестного языка с несколькими векторами известных языков (Выполнение шагов 5-6 соответствует 6 баллам)

Сравнивать попарно два вектора может быть неудобно, если у нас есть множество векторов разных текстов. 
Поэтому, мы можем сравнивать вектор на неизвестном языке со всеми другими векторами на известных языках
и найти два текста, расстояние между которыми будет минимально.

Функция принимает на вход вектор неизвестного языка, список текстовых векторов известных языков,
а также соответсвующие метки языков для каждого известного языка, например:

```py
unknown_text_vector = [0.2, 0, 0.2, 0, 0.2, 0, 0.2, 0, 0]
known_text_vectors = [
    [0, 0.2, 0, 0.1, 0, 0.49, 0, 0.3, 0],
    [0.1, 0, 0.4, 0.1, 0, 0, 0.34, 0.3, 0],
    [0, 0.2, 0, 0.1, 0, 0.49, 0, 0.3, 0.35]
]
language_labels = ['eng', 'de', 'eng']
```

Функция возвращает список, где первый элемент - предсказанная для неизвестного текста метка языка,
а второй элемент - полученное минимальное расстояние между текстом на неизвестном языке и текстом известным.
Например, для входных данных выше, будут получены расстояния `0.7349149610669251, 0.4578209256903839, 
0.8140024569987488`, а результат следующий:

```py
['de', 0.4578209256903839]
```

Если на вход подаются некорректные значения, возвращается `None`.

В данной функции необходимо использовать функцию `calculate_distance`.

Интерфейс:
```py
def predict_language_score(unknown_text_vector: list, known_text_vectors: list, language_labels: list) ->  [str, int] or None:
    pass
```

### Шаг 7. Добавить новую метрику расстояния

Существует множество метрик для сравнения расстояния между векторами.
Например, Манхетенское расстояние:

<img src="https://latex.codecogs.com/gif.latex?dist(a,&space;b)&space;=&space;{\sum_{i=1}^{n}&space;\left&space;|a_{i}&space;-&space;b_{i}&space;\right|}" title="dist(a, b) = \sqrt{\sum_{i=1}^{n} \left |a_{i} - b_{i} \right|}" />

Функция принимает на вход два вектора.

Функция возвращает значение типа `float`. Чем меньше это значение,
тем ближе два заданных вектора на координатной плоскости, а соответственно
и ближе два текста, закодированные в них.

Если на вход подаются некорректные значения, возвращается `None`.

Интерфейс:
```py
def calculate_distance_manhattan(unknown_text_vector: list, known_text_vector: list) -> float or None:
    pass
```

### Шаг 8.1. Улучшить точность предсказания 

В предыдущих шагах мы находили самый близкий вектор к вектору неизвестного текста из всех векторов.
Мы можем повысить точность предсказания, если мы будем смотреть не на самый близкий вектор, 
а на несколько самых близких векторов. Такой алгоритм называется KNN (K-nearest neighbors) или
алгоритм к-ближайших соседей (см. [подробнее](https://proglib.io/p/metod-k-blizhayshih-sosedey-k-nearest-neighbour-2021-07-19)),
где к - это количество самых близких векторов-соседей, из которых мы хотим выбрать язык текста для вектора на неизвестном языке.

### Шаг 8.2. Сравнить расстояния у нескольких ближайших соседей (Выполнение шагов 7-8.2 соответствует 8 баллам)

Функция принимает на вход вектор неизвестного языка,
список векторов на известном языке, список меток для векторов на известном языке,
параметр по умолчанию к, который обозначает количество соседей, из которых нужно делать выбор,
а также аргумент по умолчанию - название метрики для подсчета расстояния: `euclid` или `manhattan`.

Например, при параметре к=3, функция находит 3 самых близких текста к неизвестному тексту.
Затем функция определяет, каких языков больше среди найденных 3 текстов. Если больше половины
ближайших соседей имеют метку одного языка, например, "eng", значит и неизвестный текст также
написан на наглийском языке. Проиллюстрируем работу алгоритма на примере. При заданных векторе 
неизвестного текста, а также 6 векторов известных текстов на английском и немецком языках и параметре
к=3, мы получаем следующие расстояния близости: `(0.7349149610669251, 0.4578209256903839, 0.8140024569987488,
0.6552309211262851, 0.43783558557979274, 0.6995994282444776)`. Так как мы указали параметр к=3, ты мы 
выбираем три самых минимальных значения, это `(0.43783558557979274, 0.4578209256903839, 0.6552309211262851)`
c соответствующими значениями меток языков `('de', 'de', 'eng')`. Так как большее число соседей имеют
метку языка `de`, то и для неизвестного текста предсказывается и возвращается метка `de`  и значения
ближайших двух (в данном случае) соседей с этой меткой.

```py
unknown_text_vector = [0.2, 0, 0.2, 0, 0.2, 0, 0.2, 0, 0]
known_text_vectors = [
    [0, 0.2, 0, 0.1, 0, 0.49, 0, 0.3, 0],
    [0.1, 0, 0.4, 0.1, 0, 0, 0.34, 0.3, 0],
    [0, 0.2, 0, 0.1, 0, 0.49, 0, 0.3, 0.35],
    [0.11, 0, 0.34, 0.1, 0.12, 0, 0.8, 0.1234, 0.1],
    [0.1, 0, 0.4, 0.1, 0.1, 0.11, 0.34, 0.3, 0],
    [0, 0, 0.4, 0, 0, 0, 0.6, 0.3, 0.3456]
]
language_labels = ['eng', 'de', 'eng', 'eng', 'de', 'de']
k = 3
metric = 'euclid'
```

Функция возвращает список с меткой языка, а также значением - минимальным расстоянием до ближайшего соседа.

Если при сравнении заданных ближайших соседей получается равное количество схожих меток,
то выбирается метка того соседа, у которого расстояние до неизвестного текста минимально.

Если на вход подаются некорректные значения, возвращается `None`.

Интерфейс:
```py
def predict_language_knn(unknown_text_vector: list, known_text_vectors: list, language_labels: list, k=1, metric='manhattan') -> [str, int] or None:
    pass
```

### Шаг 9. Оптимизация алгоритма 

Теперь мы можем классифицировать неизвестный язык на основе языковых профилей,
а также различных примерах текстов на известном языке. Однако, работа алгоритма может быть сильно 
замедлена с ростом предсказываемых языков. Например, список уникальных слов всех языковых профилей
может сильно отличаться по размеру в зависимости от того, сколько языков есть в языковых профилях.
Следовательно, и наши векторы текстов будут сильно увеличиваться, приобретая все больше и больше нулевых значений.
С такими большими векторами, наполненными, по большей части, нулями, вычисления становятся длительными.

Вам предлагается подумать над тем, как можно упростить векторные вычисления при больших размерах векторов.

### Шаг 9.1. Использование разреженных векторов 

Одним из способов оптимизации является уменьшение размера большого вектора через удаление в нем нулевых значений.
Однако, поскольку в векторе каждая позиция несет в себе информацию об определенном уникальном слове из языкового профиля,
мы не можем потерять эту информацию. Нам необходимо составить такой вектор, в котором каждый элемент будет нести в себе 
не только значение частоты встреченного слова в языковом профиле, но и позицию этого слова в списке уникальных слов 
словаря языковых профилей. Например, при заданном списке уникальных токенов и словаре языковых профилей:

```py
features = ['boy', 'der', 'football', 'fussball', 'is', 'junge', 'playing', 'spielt', 'the']

language_profiles = {
    'eng': {'the': 0.2, 'boy': 0.2, 'is': 0.2, 'playing': 0.2, 'football': 0.2},
    'de': {'der': 0.4, 'junge': 0.2, 'fussball': 0.2, 'spielt': 0.2}
}
```

мы пытаемся закодировать предложение `The german tech specialist is playing games.`. В обычном кодировании
мы бы получили вектор:

```py
unknown_text_vector = [0, 0, 0, 0, 0.2, 0, 0.2, 0, 0.2]
```

Однако, для упрощения последующих вычислений, мы хотим упростить (разрядить) полученный нами вектор,
поэтому мы создаем разреженный вектор:

```py
unknown_text_vector = [[4, 0.2], [6, 0.2], [8, 0.2]]
```

где каждый элемент нашего вектора хранит в себе информацию о позиции в векторе,
которая имеет ненулевое значение, а также собственно частоту слова, кодированного в этой позиции из
словаря языковых профилей.

Функция как и `get_text_vector` принимает на вход текст в виде списка токенов,
а также словаря языковых профилей, из которого мы будем брать частоты слов.

Функция возвращает разреженный вектор для заданного текста.

В данной функции необходимо использовать функцию `get_features`. 
Обратите внимание, что в данном случае, функция не обязательно будет возвращать векторы одной длины,
как это делала функция `get_text_vector`, поскольку для каждого значения в векторе мы храним его позицию в списке
уникальных слов языковых профилей.

Если на вход подаются некорректные значения, возвращается `None`.

Интерфейс:
```py
def get_text_vector_sparse(original_text: list, language_profiles: dict) -> list or None:
    pass
```

### Шаг 10. Адаптировать функции для работы с разреженными векторами (Выполнение шагов 9-10 соответствует 10 баллам)

После того, как мы научились делать разреженные векторы, нам необходимо адаптировать существующие функции для работы
с разреженными векторами.

Логика функций сохраняется прежняя. 

Обратите внимание, что результаты подсчета с разреженными векторами не будут отличаться от результатов подсчета
с неразреженными векторами. Однако, значительная разница будет присутсвовать в скорости вычисления, особенно, при
большом количестве языков и наборе данных.

Интерфейс:
```py
def calculate_distance_sparse(unknown_text_vector: list, known_text_vector: list) -> float or None:
    pass
```

Интерфейс:
```py
def predict_language_knn_sparse(unknown_text_vector: list, known_text_vectors: list, language_labels: list, k=1) ->  [str, int] or None:
    pass
```
